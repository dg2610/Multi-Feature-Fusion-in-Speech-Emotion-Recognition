{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Hfk9ulIm4Yo1"
      },
      "outputs": [],
      "source": [
        "import librosa\n",
        "import soundfile\n",
        "import os, glob, pickle\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.metrics import accuracy_score"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Extracting features from audio files\n",
        "def feature_extraction(file_name):\n",
        "    with soundfile.SoundFile(file_name) as sound_file:\n",
        "        X = sound_file.read(dtype=\"float32\")\n",
        "        sample_rate=sound_file.samplerate\n",
        "        result=np.array([])\n",
        "        # STFT\n",
        "        stft=np.abs(librosa.stft(X))\n",
        "        # MFCC\n",
        "        mfccs=np.mean(librosa.feature.mfcc(y=X, sr=sample_rate, n_mfcc=50).T, axis=0)\n",
        "        result=np.hstack((result, mfccs))\n",
        "        return result"
      ],
      "metadata": {
        "id": "7CuSVf5g4a-x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Emotions present in the RAVDESS dataset\n",
        "emotions={\n",
        "  '01':'neutral',\n",
        "  '02':'calm',\n",
        "  '03':'happy',\n",
        "  '04':'sad',\n",
        "  '05':'angry',\n",
        "  '06':'fearful',\n",
        "  '07':'disgust',\n",
        "  '08':'surprised'\n",
        "}"
      ],
      "metadata": {
        "id": "0k4l95Cz4mLE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Emotions to recognize\n",
        "emotions_to_recognize=['angry','disgust','surprised','calm','neutral','happy','sad','fearful']"
      ],
      "metadata": {
        "id": "Z-KQPPlB4m8l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Data Loading and feature extraction for each sound file\n",
        "def load_data(test_size=0.2):\n",
        "    x,y=[],[]\n",
        "    for file in glob.glob('/content/drive/MyDrive/RAVDESS/**/*.wav'):\n",
        "        file_name=os.path.basename(file)\n",
        "        emotion=emotions[file_name.split(\"-\")[2]]\n",
        "        if emotion not in emotions_to_recognize:\n",
        "            continue\n",
        "        feature=feature_extraction(file)\n",
        "        x.append(feature)\n",
        "        y.append(emotion)\n",
        "    return train_test_split(np.array(x), y, test_size=test_size, random_state=9)"
      ],
      "metadata": {
        "id": "LYOjrLl84pFh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset splitting for training and testing\n",
        "x_train,x_test,y_train,y_test= load_data(test_size=0.2)"
      ],
      "metadata": {
        "id": "qTYcCOWT4t9Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# training and testing datasets\n",
        "print((x_train.shape[0], x_test.shape[0]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-kVYuJCJ4wo7",
        "outputId": "4fe26e95-870c-490a-f7cf-94882cc123b7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(1152, 288)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# the features extracted\n",
        "print(f'Features extracted: {x_train.shape[1]}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kfJZWq_H40KN",
        "outputId": "e196092d-fd18-47b9-d62a-1216880a8c7e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Features extracted: 40\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Model Initialization -> The Multi Layer Perceptron Classifier\n",
        "model=MLPClassifier(alpha=0.01, batch_size=256, epsilon=1e-08, hidden_layer_sizes=(300,), learning_rate='adaptive', max_iter=500)"
      ],
      "metadata": {
        "id": "31Kjhlet414V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Model Training\n",
        "model.fit(x_train,y_train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EAYHy3Zy44G6",
        "outputId": "6a429d01-9fea-4076-de32-38602041ecc1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "MLPClassifier(alpha=0.01, batch_size=256, hidden_layer_sizes=(300,),\n",
              "              learning_rate='adaptive', max_iter=500)"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Model Prediction\n",
        "y_pred=model.predict(x_test)"
      ],
      "metadata": {
        "id": "JtQgVKdD45vP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Model Accuracy\n",
        "accuracy=accuracy_score(y_true=y_test, y_pred=y_pred)\n",
        "print(\"Accuracy: {:.2f}%\".format(accuracy*100))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Wxk7uaY647RD",
        "outputId": "5e3d92e5-762b-4e1b-bc46-5dcff0681473"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 48.61%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x_train,x_test,y_train,y_test= load_data(test_size=0.2)\n",
        "print((x_train.shape[0], x_test.shape[0]))\n",
        "print(f'Features extracted: {x_train.shape[1]}')\n",
        "model=MLPClassifier(alpha=0.01, batch_size=256, epsilon=1e-08, hidden_layer_sizes=(300,), learning_rate='adaptive', max_iter=500)\n",
        "model.fit(x_train,y_train)\n",
        "y_pred=model.predict(x_test)\n",
        "accuracy=accuracy_score(y_true=y_test, y_pred=y_pred)\n",
        "print(\"Accuracy: {:.2f}%\".format(accuracy*100))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LoDWXJA2IEhn",
        "outputId": "f00f48eb-69d9-4ed5-c4dd-eedaba648a80"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(1152, 288)\n",
            "Features extracted: 50\n",
            "Accuracy: 50.00%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Assessing the accuracy of the model with each feature independently"
      ],
      "metadata": {
        "id": "s-xG4yg_7P8n"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def feature_extraction(file_name):\n",
        "    with soundfile.SoundFile(file_name) as sound_file:\n",
        "        X = sound_file.read(dtype=\"float32\")\n",
        "        sample_rate=sound_file.samplerate\n",
        "        result=np.array([])\n",
        "        # STFT\n",
        "        stft=np.abs(librosa.stft(X))\n",
        "        # Chroma_STFT\n",
        "        chroma=np.mean(librosa.feature.chroma_stft(S=stft, sr=sample_rate).T,axis=0)\n",
        "        result=np.hstack((result, chroma))\n",
        "        return result"
      ],
      "metadata": {
        "id": "lbKL9nXI7rzb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_train,x_test,y_train,y_test= load_data(test_size=0.2)\n",
        "print((x_train.shape[0], x_test.shape[0]))\n",
        "print(f'Features extracted: {x_train.shape[1]}')\n",
        "model=MLPClassifier(alpha=0.01, batch_size=256, epsilon=1e-08, hidden_layer_sizes=(300,), learning_rate='adaptive', max_iter=500)\n",
        "model.fit(x_train,y_train)\n",
        "y_pred=model.predict(x_test)\n",
        "accuracy=accuracy_score(y_true=y_test, y_pred=y_pred)\n",
        "print(\"Accuracy: {:.2f}%\".format(accuracy*100))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dT4FbeCK8emp",
        "outputId": "802107e5-b52e-4fa2-f99e-5daf46d490a0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(1152, 288)\n",
            "Features extracted: 12\n",
            "Accuracy: 16.67%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def feature_extraction(file_name):\n",
        "    with soundfile.SoundFile(file_name) as sound_file:\n",
        "        X = sound_file.read(dtype=\"float32\")\n",
        "        sample_rate=sound_file.samplerate\n",
        "        result=np.array([])\n",
        "        # Mel Spectogram\n",
        "        mel=np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n",
        "        result=np.hstack((result, mel))\n",
        "        return result"
      ],
      "metadata": {
        "id": "1jcHbgJW80ar"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_train,x_test,y_train,y_test= load_data(test_size=0.2)\n",
        "print((x_train.shape[0], x_test.shape[0]))\n",
        "print(f'Features extracted: {x_train.shape[1]}')\n",
        "model=MLPClassifier(alpha=0.01, batch_size=256, epsilon=1e-08, hidden_layer_sizes=(300,), learning_rate='adaptive', max_iter=500)\n",
        "model.fit(x_train,y_train)\n",
        "y_pred=model.predict(x_test)\n",
        "accuracy=accuracy_score(y_true=y_test, y_pred=y_pred)\n",
        "print(\"Accuracy: {:.2f}%\".format(accuracy*100))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ey3dMDPc9Cbv",
        "outputId": "8cd8ebb2-a7bc-4e60-9582-1d7cf28fec5e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(1152, 288)\n",
            "Features extracted: 128\n",
            "Accuracy: 40.28%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def feature_extraction(file_name):\n",
        "    with soundfile.SoundFile(file_name) as sound_file:\n",
        "        X = sound_file.read(dtype=\"float32\")\n",
        "        sample_rate=sound_file.samplerate\n",
        "        result=np.array([])\n",
        "        zcr = np.mean(librosa.feature.zero_crossing_rate(y=X).T, axis=0)\n",
        "        result=np.hstack((result, zcr))\n",
        "        return result"
      ],
      "metadata": {
        "id": "aw0FZveZ9IyW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_train,x_test,y_train,y_test= load_data(test_size=0.2)\n",
        "print((x_train.shape[0], x_test.shape[0]))\n",
        "print(f'Features extracted: {x_train.shape[1]}')\n",
        "model=MLPClassifier(alpha=0.01, batch_size=256, epsilon=1e-08, hidden_layer_sizes=(300,), learning_rate='adaptive', max_iter=500)\n",
        "model.fit(x_train,y_train)\n",
        "y_pred=model.predict(x_test)\n",
        "accuracy=accuracy_score(y_true=y_test, y_pred=y_pred)\n",
        "print(\"Accuracy: {:.2f}%\".format(accuracy*100))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5z3DayE99TQq",
        "outputId": "6f3499d3-bd39-49c4-e005-6aa34c767b4d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(1152, 288)\n",
            "Features extracted: 1\n",
            "Accuracy: 20.14%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def feature_extraction(file_name):\n",
        "    with soundfile.SoundFile(file_name) as sound_file:\n",
        "        X = sound_file.read(dtype=\"float32\")\n",
        "        sample_rate=sound_file.samplerate\n",
        "        result=np.array([])\n",
        "        cqt = np.mean(librosa.feature.chroma_cqt(y=X, sr=sample_rate).T, axis=0)\n",
        "        result = np.hstack((result, cqt))\n",
        "        return result"
      ],
      "metadata": {
        "id": "t7rhOJnC9YVU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_train,x_test,y_train,y_test= load_data(test_size=0.2)\n",
        "print((x_train.shape[0], x_test.shape[0]))\n",
        "print(f'Features extracted: {x_train.shape[1]}')\n",
        "model=MLPClassifier(alpha=0.01, batch_size=256, epsilon=1e-08, hidden_layer_sizes=(300,), learning_rate='adaptive', max_iter=500)\n",
        "model.fit(x_train,y_train)\n",
        "y_pred=model.predict(x_test)\n",
        "accuracy=accuracy_score(y_true=y_test, y_pred=y_pred)\n",
        "print(\"Accuracy: {:.2f}%\".format(accuracy*100))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h7k4bp0e9ekM",
        "outputId": "d110acdf-d5b4-47d5-8d6b-83d32560f558"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(1152, 288)\n",
            "Features extracted: 12\n",
            "Accuracy: 26.74%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def feature_extraction(file_name):\n",
        "    with soundfile.SoundFile(file_name) as sound_file:\n",
        "        X = sound_file.read(dtype=\"float32\")\n",
        "        sample_rate=sound_file.samplerate\n",
        "        result=np.array([])\n",
        "        chroma_cens = np.mean(librosa.feature.chroma_cens(y=X, sr=sample_rate).T, axis=0)\n",
        "        result = np.hstack((result, chroma_cens))\n",
        "        return result"
      ],
      "metadata": {
        "id": "aY72XF1F9hQg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_train,x_test,y_train,y_test= load_data(test_size=0.2)\n",
        "print((x_train.shape[0], x_test.shape[0]))\n",
        "print(f'Features extracted: {x_train.shape[1]}')\n",
        "model=MLPClassifier(alpha=0.01, batch_size=256, epsilon=1e-08, hidden_layer_sizes=(300,), learning_rate='adaptive', max_iter=500)\n",
        "model.fit(x_train,y_train)\n",
        "y_pred=model.predict(x_test)\n",
        "accuracy=accuracy_score(y_true=y_test, y_pred=y_pred)\n",
        "print(\"Accuracy: {:.2f}%\".format(accuracy*100))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_mbmlbTK-qOW",
        "outputId": "be0223b5-57ad-4dc7-b94f-2fccf742558a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(1152, 288)\n",
            "Features extracted: 12\n",
            "Accuracy: 26.74%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def feature_extraction(file_name):\n",
        "    with soundfile.SoundFile(file_name) as sound_file:\n",
        "        X = sound_file.read(dtype=\"float32\")\n",
        "        sample_rate=sound_file.samplerate\n",
        "        result=np.array([])\n",
        "        stft=np.abs(librosa.stft(X))\n",
        "        chroma_spectral_poly_features = np.mean(librosa.feature.poly_features(S=stft, order=2).T, axis=0)\n",
        "        result = np.hstack((result, chroma_spectral_poly_features))\n",
        "        return result"
      ],
      "metadata": {
        "id": "vKa192B_-tMa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_train,x_test,y_train,y_test= load_data(test_size=0.2)\n",
        "print((x_train.shape[0], x_test.shape[0]))\n",
        "print(f'Features extracted: {x_train.shape[1]}')\n",
        "model=MLPClassifier(alpha=0.01, batch_size=256, epsilon=1e-08, hidden_layer_sizes=(300,), learning_rate='adaptive', max_iter=500)\n",
        "model.fit(x_train,y_train)\n",
        "y_pred=model.predict(x_test)\n",
        "accuracy=accuracy_score(y_true=y_test, y_pred=y_pred)\n",
        "print(\"Accuracy: {:.2f}%\".format(accuracy*100))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mMkBahLE-7Pu",
        "outputId": "c10677f0-da19-4795-a070-80c07d6e22cc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(1152, 288)\n",
            "Features extracted: 3\n",
            "Accuracy: 30.21%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def feature_extraction(file_name):\n",
        "    with soundfile.SoundFile(file_name) as sound_file:\n",
        "        X = sound_file.read(dtype=\"float32\")\n",
        "        sample_rate=sound_file.samplerate\n",
        "        result=np.array([])\n",
        "        stft=np.abs(librosa.stft(X))\n",
        "        chroma_spectral_centroid = np.mean(librosa.feature.spectral_centroid(S=stft, sr=sample_rate).T, axis=0)\n",
        "        result = np.hstack((result, chroma_spectral_centroid))\n",
        "        return result"
      ],
      "metadata": {
        "id": "YQ1fQSyQAATz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_train,x_test,y_train,y_test= load_data(test_size=0.2)\n",
        "print((x_train.shape[0], x_test.shape[0]))\n",
        "print(f'Features extracted: {x_train.shape[1]}')\n",
        "model=MLPClassifier(alpha=0.01, batch_size=256, epsilon=1e-08, hidden_layer_sizes=(300,), learning_rate='adaptive', max_iter=500)\n",
        "model.fit(x_train,y_train)\n",
        "y_pred=model.predict(x_test)\n",
        "accuracy=accuracy_score(y_true=y_test, y_pred=y_pred)\n",
        "print(\"Accuracy: {:.2f}%\".format(accuracy*100))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KyzO01bXAg3F",
        "outputId": "08e0b3bd-4458-43a2-c606-0296b2ac9234"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(1152, 288)\n",
            "Features extracted: 1\n",
            "Accuracy: 12.50%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def feature_extraction(file_name):\n",
        "    with soundfile.SoundFile(file_name) as sound_file:\n",
        "        X = sound_file.read(dtype=\"float32\")\n",
        "        sample_rate=sound_file.samplerate\n",
        "        result=np.array([])\n",
        "        stft=np.abs(librosa.stft(X))\n",
        "        chroma_spectral_bandwidth = np.mean(librosa.feature.spectral_bandwidth(S=stft, sr=sample_rate).T, axis=0)\n",
        "        result = np.hstack((result, chroma_spectral_bandwidth))\n",
        "        return result"
      ],
      "metadata": {
        "id": "zmb46YWuAhzd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_train,x_test,y_train,y_test= load_data(test_size=0.2)\n",
        "print((x_train.shape[0], x_test.shape[0]))\n",
        "print(f'Features extracted: {x_train.shape[1]}')\n",
        "model=MLPClassifier(alpha=0.01, batch_size=256, epsilon=1e-08, hidden_layer_sizes=(300,), learning_rate='adaptive', max_iter=500)\n",
        "model.fit(x_train,y_train)\n",
        "y_pred=model.predict(x_test)\n",
        "accuracy=accuracy_score(y_true=y_test, y_pred=y_pred)\n",
        "print(\"Accuracy: {:.2f}%\".format(accuracy*100))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zUNCQDXlAn-i",
        "outputId": "7a0cc88e-a13b-49c4-8de2-6999edd630cc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(1152, 288)\n",
            "Features extracted: 1\n",
            "Accuracy: 12.50%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def feature_extraction(file_name):\n",
        "    with soundfile.SoundFile(file_name) as sound_file:\n",
        "        X = sound_file.read(dtype=\"float32\")\n",
        "        sample_rate=sound_file.samplerate\n",
        "        result=np.array([])\n",
        "        stft=np.abs(librosa.stft(X))\n",
        "        chroma_spectral_contrast = np.mean(librosa.feature.spectral_contrast(S=stft, sr=sample_rate).T, axis=0)\n",
        "        result = np.hstack((result, chroma_spectral_contrast))\n",
        "        return result"
      ],
      "metadata": {
        "id": "MIvE1U9PAp1_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_train,x_test,y_train,y_test= load_data(test_size=0.2)\n",
        "print((x_train.shape[0], x_test.shape[0]))\n",
        "print(f'Features extracted: {x_train.shape[1]}')\n",
        "model=MLPClassifier(alpha=0.01, batch_size=256, epsilon=1e-08, hidden_layer_sizes=(300,), learning_rate='adaptive', max_iter=500)\n",
        "model.fit(x_train,y_train)\n",
        "y_pred=model.predict(x_test)\n",
        "accuracy=accuracy_score(y_true=y_test, y_pred=y_pred)\n",
        "print(\"Accuracy: {:.2f}%\".format(accuracy*100))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cOVu90acAwp6",
        "outputId": "99afec9e-4436-480a-8f82-f63f49c23224"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(1152, 288)\n",
            "Features extracted: 7\n",
            "Accuracy: 23.26%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def feature_extraction(file_name):\n",
        "    with soundfile.SoundFile(file_name) as sound_file:\n",
        "        X = sound_file.read(dtype=\"float32\")\n",
        "        sample_rate=sound_file.samplerate\n",
        "        result=np.array([])\n",
        "        stft=np.abs(librosa.stft(X))\n",
        "        chroma_spectral_flatness = np.mean(librosa.feature.spectral_flatness(S=stft).T, axis=0)\n",
        "        result = np.hstack((result, chroma_spectral_flatness))\n",
        "        return result"
      ],
      "metadata": {
        "id": "H9SRLPd8AymV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_train,x_test,y_train,y_test= load_data(test_size=0.2)\n",
        "print((x_train.shape[0], x_test.shape[0]))\n",
        "print(f'Features extracted: {x_train.shape[1]}')\n",
        "model=MLPClassifier(alpha=0.01, batch_size=256, epsilon=1e-08, hidden_layer_sizes=(300,), learning_rate='adaptive', max_iter=500)\n",
        "model.fit(x_train,y_train)\n",
        "y_pred=model.predict(x_test)\n",
        "accuracy=accuracy_score(y_true=y_test, y_pred=y_pred)\n",
        "print(\"Accuracy: {:.2f}%\".format(accuracy*100))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ICSFYF4tA3yO",
        "outputId": "22451214-ef62-478a-bd94-c0392702d1ae"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(1152, 288)\n",
            "Features extracted: 1\n",
            "Accuracy: 11.11%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def feature_extraction(file_name):\n",
        "    with soundfile.SoundFile(file_name) as sound_file:\n",
        "        X = sound_file.read(dtype=\"float32\")\n",
        "        sample_rate=sound_file.samplerate\n",
        "        result=np.array([])\n",
        "        stft=np.abs(librosa.stft(X))\n",
        "        chroma_spectral_rolloff = np.mean(librosa.feature.spectral_rolloff(S=stft, sr=sample_rate).T, axis=0)\n",
        "        result = np.hstack((result, chroma_spectral_rolloff))\n",
        "        return result"
      ],
      "metadata": {
        "id": "zOEMVNvsA6Yg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_train,x_test,y_train,y_test= load_data(test_size=0.2)\n",
        "print((x_train.shape[0], x_test.shape[0]))\n",
        "print(f'Features extracted: {x_train.shape[1]}')\n",
        "model=MLPClassifier(alpha=0.01, batch_size=256, epsilon=1e-08, hidden_layer_sizes=(300,), learning_rate='adaptive', max_iter=500)\n",
        "model.fit(x_train,y_train)\n",
        "y_pred=model.predict(x_test)\n",
        "accuracy=accuracy_score(y_true=y_test, y_pred=y_pred)\n",
        "print(\"Accuracy: {:.2f}%\".format(accuracy*100))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A6h83qWOBAXV",
        "outputId": "b13ae216-3ab1-406a-d32e-c55f95e2c74c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(1152, 288)\n",
            "Features extracted: 1\n",
            "Accuracy: 12.50%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def feature_extraction(file_name):\n",
        "    with soundfile.SoundFile(file_name) as sound_file:\n",
        "        X = sound_file.read(dtype=\"float32\")\n",
        "        sample_rate=sound_file.samplerate\n",
        "        result=np.array([])\n",
        "        rms = np.mean(librosa.feature.rms(y=X).T, axis=0)\n",
        "        result = np.hstack((result, rms))\n",
        "        return result"
      ],
      "metadata": {
        "id": "lDS40Y7GBCg1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_train,x_test,y_train,y_test= load_data(test_size=0.2)\n",
        "print((x_train.shape[0], x_test.shape[0]))\n",
        "print(f'Features extracted: {x_train.shape[1]}')\n",
        "model=MLPClassifier(alpha=0.01, batch_size=256, epsilon=1e-08, hidden_layer_sizes=(300,), learning_rate='adaptive', max_iter=500)\n",
        "model.fit(x_train,y_train)\n",
        "y_pred=model.predict(x_test)\n",
        "accuracy=accuracy_score(y_true=y_test, y_pred=y_pred)\n",
        "print(\"Accuracy: {:.2f}%\".format(accuracy*100))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S9QKT_49BKBN",
        "outputId": "a8f92429-4bdd-48b2-d4b9-9195817a5d81"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(1152, 288)\n",
            "Features extracted: 1\n",
            "Accuracy: 27.43%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def feature_extraction(file_name):\n",
        "    with soundfile.SoundFile(file_name) as sound_file:\n",
        "        X = sound_file.read(dtype=\"float32\")\n",
        "        sample_rate=sound_file.samplerate\n",
        "        result=np.array([])\n",
        "        harmonic = np.abs(librosa.effects.harmonic(X))\n",
        "        tonnetz = np.mean(librosa.feature.tonnetz(y=harmonic, sr=sample_rate).T, axis=0)\n",
        "        result = np.hstack((result, tonnetz))\n",
        "        return result"
      ],
      "metadata": {
        "id": "L6NxcM6-BMMZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_train,x_test,y_train,y_test= load_data(test_size=0.2)\n",
        "print((x_train.shape[0], x_test.shape[0]))\n",
        "print(f'Features extracted: {x_train.shape[1]}')\n",
        "model=MLPClassifier(alpha=0.01, batch_size=256, epsilon=1e-08, hidden_layer_sizes=(300,), learning_rate='adaptive', max_iter=500)\n",
        "model.fit(x_train,y_train)\n",
        "y_pred=model.predict(x_test)\n",
        "accuracy=accuracy_score(y_true=y_test, y_pred=y_pred)\n",
        "print(\"Accuracy: {:.2f}%\".format(accuracy*100))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7hQktzBmBSVa",
        "outputId": "fbf9d20d-9208-46e9-c70a-e7f8e74b5f05"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(1152, 288)\n",
            "Features extracted: 6\n",
            "Accuracy: 15.97%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def feature_extraction(file_name):\n",
        "    with soundfile.SoundFile(file_name) as sound_file:\n",
        "        X = sound_file.read(dtype=\"float32\")\n",
        "        sample_rate=sound_file.samplerate\n",
        "        result=np.array([])\n",
        "        cqt = np.mean(librosa.feature.chroma_cqt(y=X, sr=sample_rate).T, axis=0)\n",
        "        result = np.hstack((result, cqt))\n",
        "        return result"
      ],
      "metadata": {
        "id": "W0mD-gzyEO1G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_train,x_test,y_train,y_test= load_data(test_size=0.2)\n",
        "print((x_train.shape[0], x_test.shape[0]))\n",
        "print(f'Features extracted: {x_train.shape[1]}')\n",
        "model=MLPClassifier(alpha=0.01, batch_size=256, epsilon=1e-08, hidden_layer_sizes=(300,), learning_rate='adaptive', max_iter=500)\n",
        "model.fit(x_train,y_train)\n",
        "y_pred=model.predict(x_test)\n",
        "accuracy=accuracy_score(y_true=y_test, y_pred=y_pred)\n",
        "print(\"Accuracy: {:.2f}%\".format(accuracy*100))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ROy2EcBRETkp",
        "outputId": "726e0fd4-1811-4a69-b3d0-2bc744b4bc27"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(1152, 288)\n",
            "Features extracted: 12\n",
            "Accuracy: 27.08%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now we have data on how well each feature can help in our SER\n",
        "Tonnetz: 15.97%,\n",
        "Root Mean Square: 27.43%,\n",
        "chroma_spectral_centroid: 12.5%,\n",
        "chroma_spectral_bandwidth: 12.5%,\n",
        "chroma_spectral_contrast: 23.26%,\n",
        "chroma_spectral_flatness: 11.11%,\n",
        "chroma_spectral_rolloff: 12.5%,\n",
        "chroma_spectral_poly_features: 30.21% (Order: 2),\n",
        "chroma_CENS: 26.74%,\n",
        "CQT: 27.08 %,\n",
        "Zero Crossing Data: 20.14%,\n",
        "Mel spectrogram: 40.28%,\n",
        "MFCC: 48.61%,\n",
        "Chroma_STFT: 16.67%"
      ],
      "metadata": {
        "id": "J_dU58HtBWbP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can start experimenting different combinations of these features and see which of these when fused improves accuracy"
      ],
      "metadata": {
        "id": "FJOIX1ASFnkV"
      }
    }
  ]
}